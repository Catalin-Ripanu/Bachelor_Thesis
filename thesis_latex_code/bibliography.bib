@inproceedings{goodfellow2014generative,
  title     = {Generative adversarial nets},
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle = {Advances in neural information processing systems},
  pages     = {2672--2680},
  year      = {2014}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@book{nielsen2001quantum,
  title     = {Quantum computation and quantum information},
  author    = {Nielsen, Michael A and Chuang, Isaac L},
  volume    = {2},
  year      = {2001},
  publisher = {Cambridge university press Cambridge}
}

@inproceedings{furer2008solving,
  title        = {Solving NP-complete problems with quantum search},
  author       = {F{\"u}rer, Martin},
  booktitle    = {Latin American Symposium on Theoretical Informatics},
  pages        = {784--792},
  year         = {2008},
  organization = {Springer}
}

@article{chatterjee2024solving,
  title     = {Solving various NP-hard problems using exponentially fewer qubits on a quantum computer},
  author    = {Chatterjee, Yagnik and Bourreau, Eric and Ran{\v{c}}i{\'c}, Marko J},
  journal   = {Physical Review A},
  volume    = {109},
  number    = {5},
  pages     = {052441},
  year      = {2024},
  publisher = {APS}
}

@article{dunjko2018machine,
  title     = {Machine learning \& artificial intelligence in the quantum domain: a review of recent progress},
  author    = {Dunjko, Vedran and Briegel, Hans J},
  journal   = {Reports on Progress in Physics},
  volume    = {81},
  number    = {7},
  pages     = {074001},
  year      = {2018},
  publisher = {IOP Publishing}
}

@article{cerezo2021variational,
  title     = {Variational quantum algorithms},
  author    = {Cerezo, Marco and Arrasmith, Andrew and Babbush, Ryan and Benjamin, Simon C and Endo, Suguru and Fujii, Keisuke and McClean, Jarrod R and Mitarai, Kosuke and Yuan, Xiao and Cincio, Lukasz and others},
  journal   = {Nature Reviews Physics},
  volume    = {3},
  number    = {9},
  pages     = {625--644},
  year      = {2021},
  publisher = {Nature Publishing Group UK London}
}

@article{liashchynskyi2019grid,
  title   = {Grid search, random search, genetic algorithm: a big comparison for NAS},
  author  = {Liashchynskyi, Petro and Liashchynskyi, Pavlo},
  journal = {arXiv preprint arXiv:1912.06059},
  year    = {2019}
}

@inproceedings{ogutu2012genomic,
  title        = {Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions},
  author       = {Ogutu, Joseph O and Schulz-Streeck, Torben and Piepho, Hans-Peter},
  booktitle    = {BMC proceedings},
  volume       = {6},
  pages        = {1--6},
  year         = {2012},
  organization = {Springer}
}

@article{abbas2021power,
  title={The power of quantum neural networks},
  author={Abbas, Amira and Sutter, David and Zoufal, Christa and Lucchi, Aur{\'e}lien and Figalli, Alessio and Woerner, Stefan},
  journal={Nature Computational Science},
  volume={1},
  number={6},
  pages={403--409},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@article{pon2021hyperparameter,
  title   = {Hyperparameter tuning of deep learning models in keras},
  author  = {Pon, Mohamad Zaim Awang and KK, Krishna Prakash},
  journal = {Sparklinglight Transactions on Artificial Intelligence and Quantum Computing (STAIQC)},
  volume  = {1},
  number  = {1},
  pages   = {36--40},
  year    = {2021}
}

@inproceedings{fan2024quantum,
  title     = {Quantum-Inspired Neural Network with Runge-Kutta Method},
  author    = {Fan, Zipeng and Zhang, Jing and Zhang, Peng and Lin, Qianxi and Gao, Hui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {38},
  number    = {16},
  pages     = {17977--17984},
  year      = {2024}
}

@misc{berrar2019cross,
  title  = {Cross-validation.},
  author = {Berrar, Daniel and others},
  year   = {2019}
}

@article{popescu2009multilayer,
  title     = {Multilayer perceptron and neural networks},
  author    = {Popescu, Marius-Constantin and Balas, Valentina E and Perescu-Popescu, Liliana and Mastorakis, Nikos},
  journal   = {WSEAS Transactions on Circuits and Systems},
  volume    = {8},
  number    = {7},
  pages     = {579--588},
  year      = {2009},
  publisher = {World Scientific and Engineering Academy and Society (WSEAS) Stevens Point~â€¦}
}

@article{gulde2003implementation,
  title     = {Implementation of the Deutsch--Jozsa algorithm on an ion-trap quantum computer},
  author    = {Gulde, Stephan and Riebe, Mark and Lancaster, Gavin PT and Becher, Christoph and Eschner, J{\"u}rgen and H{\"a}ffner, Hartmut and Schmidt-Kaler, Ferdinand and Chuang, Isaac L and Blatt, Rainer},
  journal   = {Nature},
  volume    = {421},
  number    = {6918},
  pages     = {48--50},
  year      = {2003},
  publisher = {Nature Publishing Group UK London}
}

@article{weinstein2001implementation,
  title     = {Implementation of the quantum Fourier transform},
  author    = {Weinstein, Yaakov S and Pravia, MA and Fortunato, EM and Lloyd, Seth and Cory, David G},
  journal   = {Physical review letters},
  volume    = {86},
  number    = {9},
  pages     = {1889},
  year      = {2001},
  publisher = {APS}
}

@article{o2019quantum,
  title     = {Quantum phase estimation of multiple eigenvalues for small-scale (noisy) experiments},
  author    = {O'Brien, Thomas E and Tarasinski, Brian and Terhal, Barbara M},
  journal   = {New Journal of Physics},
  volume    = {21},
  number    = {2},
  pages     = {023022},
  year      = {2019},
  publisher = {IOP Publishing}
}

@article{shi2017coherence,
  title     = {Coherence depletion in the Grover quantum search algorithm},
  author    = {Shi, Hai-Long and Liu, Si-Yuan and Wang, Xiao-Hui and Yang, Wen-Li and Yang, Zhan-Ying and Fan, Heng},
  journal   = {Physical Review A},
  volume    = {95},
  number    = {3},
  pages     = {032307},
  year      = {2017},
  publisher = {APS}
}

@inproceedings{NIPS2017_a96b65a7,
  author    = {Li, Yuanzhi and Yuan, Yang},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Convergence Analysis of Two-layer Neural Networks with ReLU Activation},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/a96b65a721e561e1e3de768ac819ffbb-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@article{srivastava2014dropout,
  title     = {Dropout: a simple way to prevent neural networks from overfitting},
  author    = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal   = {The journal of machine learning research},
  volume    = {15},
  number    = {1},
  pages     = {1929--1958},
  year      = {2014},
  publisher = {JMLR. org}
}

@misc{cordonnier2020relationship,
      title={On the Relationship between Self-Attention and Convolutional Layers}, 
      author={Jean-Baptiste Cordonnier and Andreas Loukas and Martin Jaggi},
      year={2020},
      eprint={1911.03584},
      archivePrefix={arXiv},
      primaryClass={id='cs.LG' full_name='Machine Learning' is_active=True alt_name=None in_archive='cs' is_general=False description='Papers on all aspects of machine learning research (supervised, unsupervised, reinforcement learning, bandit problems, and so on) including also robustness, explanation, fairness, and methodology. cs.LG is also an appropriate primary category for applications of machine learning methods.'}
}

@article{loshchilov2017decoupled,
  title   = {Decoupled weight decay regularization},
  author  = {Loshchilov, Ilya and Hutter, Frank},
  journal = {arXiv preprint arXiv:1711.05101},
  year    = {2017}
}

@INPROCEEDINGS{7986470,
  author={Qolomany, Basheer and Maabreh, Majdi and Al-Fuqaha, Ala and Gupta, Ajay and Benhaddou, Driss},
  booktitle={2017 13th International Wireless Communications and Mobile Computing Conference (IWCMC)}, 
  title={Parameters optimization of deep learning models using Particle swarm optimization}, 
  year={2017},
  volume={},
  number={},
  pages={1285-1290},
  keywords={Machine learning;Neurons;Computational modeling;Optimization;Biological neural networks;Sociology;Statistics;smart building services;deep machine learning;parameter optimization;particle swarm optimization},
  doi={10.1109/IWCMC.2017.7986470}}


@InProceedings{pmlr-v70-kim17b,
  title = 	 {{S}plit{N}et: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization},
  author =       {Juyong Kim and Yookoon Park and Gunhee Kim and Sung Ju Hwang},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1866--1874},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/kim17b/kim17b.pdf},
  url = 	 {https://proceedings.mlr.press/v70/kim17b.html},
  abstract = 	 {We propose a novel deep neural network that is both lightweight and effectively structured for model parallelization. Our network, which we name as SplitNet, automatically learns to split the network weights into either a set or a hierarchy of multiple groups that use disjoint sets of features, by learning both the class-to-group and feature-to-group assignment matrices along with the network weights. This produces a tree-structured network that involves no connection between branched subtrees of semantically disparate class groups. SplitNet thus greatly reduces the number of parameters and requires significantly less computations, and is also embarrassingly model parallelizable at test time, since the network evaluation for each subnetwork is completely independent except for the shared lower layer weights that can be duplicated over multiple processors. We validate our method with two deep network models (ResNet and AlexNet) on two different datasets (CIFAR-100 and ILSVRC 2012) for image classification, on which our method obtains networks with significantly reduced number of parameters while achieving comparable or superior classification accuracies over original full deep networks, and accelerated test speed with multiple GPUs.}
}


@article{wen2021convolutional,
  title     = {Convolutional neural network with automatic learning rate scheduler for fault classification},
  author    = {Wen, Long and Gao, Liang and Li, Xinyu and Zeng, Bing},
  journal   = {IEEE Transactions on Instrumentation and Measurement},
  volume    = {70},
  pages     = {1--12},
  year      = {2021},
  publisher = {IEEE}
}

@inproceedings{bottou2010large,
  title        = {Large-scale machine learning with stochastic gradient descent},
  author       = {Bottou, L{\'e}on},
  booktitle    = {Proceedings of COMPSTAT'2010: 19th International Conference on Computational StatisticsParis France, August 22-27, 2010 Keynote, Invited and Contributed Papers},
  pages        = {177--186},
  year         = {2010},
  organization = {Springer}
}

@inproceedings{zhang2018improved,
  title        = {Improved adam optimizer for deep neural networks},
  author       = {Zhang, Zijun},
  booktitle    = {2018 IEEE/ACM 26th international symposium on quality of service (IWQoS)},
  pages        = {1--2},
  year         = {2018},
  organization = {Ieee}
}

@article{zamanlooy2013efficient,
  title     = {Efficient VLSI implementation of neural networks with hyperbolic tangent activation function},
  author    = {Zamanlooy, Babak and Mirhassani, Mitra},
  journal   = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  volume    = {22},
  number    = {1},
  pages     = {39--48},
  year      = {2013},
  publisher = {IEEE}
}

@inproceedings{han1995influence,
  title        = {The influence of the sigmoid function parameters on the speed of backpropagation learning},
  author       = {Han, Jun and Moraga, Claudio},
  booktitle    = {International workshop on artificial neural networks},
  pages        = {195--201},
  year         = {1995},
  organization = {Springer}
}

@inproceedings{hinton2011transforming,
  title        = {Transforming auto-encoders},
  author       = {Hinton, Geoffrey E and Krizhevsky, Alex and Wang, Sida D},
  booktitle    = {Artificial Neural Networks and Machine Learning--ICANN 2011: 21st International Conference on Artificial Neural Networks, Espoo, Finland, June 14-17, 2011, Proceedings, Part I 21},
  pages        = {44--51},
  year         = {2011},
  organization = {Springer}
}

@misc{alvarez2018learning,
  title         = {Learning the Number of Neurons in Deep Networks},
  author        = {Jose M Alvarez and Mathieu Salzmann},
  year          = {2018},
  eprint        = {1611.06321},
  archiveprefix = {arXiv},
  primaryclass  = {id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}

@InProceedings{Szegedy_2015_CVPR,
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
title = {Going Deeper With Convolutions},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@article{jiang2021transgan,
  title   = {Transgan: Two pure transformers can make one strong gan, and that can scale up},
  author  = {Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  pages   = {14745--14758},
  year    = {2021}
}

@article{Comajoan_Cara_2024,
  title     = {Quantum Vision Transformers for Quark-Gluon Classification},
  volume    = {13},
  issn      = {2075-1680},
  url       = {http://dx.doi.org/10.3390/axioms13050323},
  doi       = {10.3390/axioms13050323},
  number    = {5},
  journal   = {Axioms},
  publisher = {MDPI AG},
  author    = {Comajoan Cara, MarÃ§al and Dahale, Gopal Ramesh and Dong, Zhongtian and Forestano, Roy T. and Gleyzer, Sergei and Justice, Daniel and Kong, Kyoungchul and Magorsch, Tom and Matchev, Konstantin T. and Matcheva, Katia and Unlu, Eyup B.},
  year      = {2024},
  month     = may,
  pages     = {323}
}

@article{ILSVRC15,
  author  = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title   = { {ImageNet Large Scale Visual Recognition Challenge} },
  year    = {2015},
  journal = {International Journal of Computer Vision (IJCV)},
  doi     = {10.1007/s11263-015-0816-y},
  volume  = {115},
  number  = {3},
  pages   = {211-252}
}

@article{weiss2016survey,
  title     = {A survey of transfer learning},
  author    = {Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
  journal   = {Journal of Big data},
  volume    = {3},
  pages     = {1--40},
  year      = {2016},
  publisher = {Springer}
}

@article{voita2019analyzing,
  title   = {Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned},
  author  = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  journal = {arXiv preprint arXiv:1905.09418},
  year    = {2019}
}

@inproceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@article{benedetti2019parameterized,
  title     = {Parameterized quantum circuits as machine learning models},
  author    = {Benedetti, Marcello and Lloyd, Erika and Sack, Stefan and Fiorentini, Mattia},
  journal   = {Quantum Science and Technology},
  volume    = {4},
  number    = {4},
  pages     = {043001},
  year      = {2019},
  publisher = {IOP Publishing}
}

@article{he2020infusing,
  title   = {Infusing disease knowledge into BERT for health question answering, medical inference and disease name recognition},
  author  = {He, Yun and Zhu, Ziwei and Zhang, Yin and Chen, Qin and Caverlee, James},
  journal = {arXiv preprint arXiv:2010.03746},
  year    = {2020}
}

@article{lecun2010mnist,
  title   = {MNIST handwritten digit database},
  author  = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume  = {2},
  year    = {2010}
}

@article{Reyes_2021,
  title     = {Simulation of quantum many-body systems on Amazon cloud},
  volume    = {261},
  issn      = {0010-4655},
  url       = {http://dx.doi.org/10.1016/j.cpc.2020.107750},
  doi       = {10.1016/j.cpc.2020.107750},
  journal   = {Computer Physics Communications},
  publisher = {Elsevier BV},
  author    = {Reyes, Justin A. and Marinescu, Dan C. and Mucciolo, Eduardo R.},
  year      = {2021},
  month     = apr,
  pages     = {107750}
}

@inproceedings{Mykhailova_2023,
  title     = {Teaching Quantum Computing Using Microsoft Quantum Development Kit and Azure Quantum},
  url       = {http://dx.doi.org/10.1109/QCE57702.2023.20320},
  doi       = {10.1109/qce57702.2023.20320},
  booktitle = {2023 IEEE International Conference on Quantum Computing and Engineering (QCE)},
  publisher = {IEEE},
  author    = {Mykhailova, Mariia},
  year      = {2023},
  month     = sep
}

@misc{kalai2023googles,
  title         = {Google's Quantum Supremacy Claim: Data, Documentation, and Discussion},
  author        = {Gil Kalai and Yosef Rinott and Tomer Shoham},
  year          = {2023},
  eprint        = {2210.12753},
  archiveprefix = {arXiv},
  primaryclass  = {id='quant-ph' full_name='Quantum Physics' is_active=True alt_name=None in_archive='quant-ph' is_general=False description=None}
}

@article{Santos_2016,
  title     = {O Computador QuÃ¢ntico da IBM e o IBM Quantum Experience},
  volume    = {39},
  issn      = {1806-1117},
  url       = {http://dx.doi.org/10.1590/1806-9126-RBEF-2016-0155},
  doi       = {10.1590/1806-9126-rbef-2016-0155},
  number    = {1},
  journal   = {Revista Brasileira de Ensino de FÃ­sica},
  publisher = {FapUNIFESP (SciELO)},
  author    = {Santos, Alan C.},
  year      = {2016},
  month     = sep
}

@techreport{Krizhevsky09learningmultiple,
  author      = {Alex Krizhevsky},
  title       = {Learning multiple layers of features from tiny images},
  institution = {},
  year        = {2009}
}

@article{dosovitskiy2020,
  title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal = {arXiv preprint arXiv:2010.11929},
  year    = {2020}
}

@inproceedings{zhao2020diffaugment,
  title     = {Differentiable Augmentation for Data-Efficient GAN Training},
  author    = {Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song},
  booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
  year      = {2020}
}

@article{liu2016large,
  title   = {Large-margin softmax loss for convolutional neural networks},
  author  = {Liu, Weiyang and Wen, Yandong and Yu, Zhiding and Yang, Meng},
  journal = {arXiv preprint arXiv:1612.02295},
  year    = {2016}
}

@article{hendrycks2016gaussian,
  title   = {Gaussian error linear units (gelus)},
  author  = {Hendrycks, Dan and Gimpel, Kevin},
  journal = {arXiv preprint arXiv:1606.08415},
  year    = {2016}
}

@article{wu2018prodsumnet,
  title={ProdSumNet: reducing model parameters in deep neural networks via product-of-sums matrix decompositions},
  author={Wu, Chai Wah},
  journal={arXiv preprint arXiv:1809.02209},
  year={2018}
}

@article{azadbakht2022drastically,
  title={Drastically Reducing the Number of Trainable Parameters in Deep CNNs by Inter-layer Kernel-sharing},
  author={Azadbakht, Alireza and Kheradpisheh, Saeed Reza and Khalfaoui-Hassani, Ismail and Masquelier, Timoth{\'e}e},
  journal={arXiv preprint arXiv:2210.14151},
  year={2022}
}

@inproceedings{xu2020reluplex,
  title        = {Reluplex made more practical: Leaky ReLU},
  author       = {Xu, Jin and Li, Zishan and Du, Bowen and Zhang, Miaomiao and Liu, Jing},
  booktitle    = {2020 IEEE Symposium on Computers and communications (ISCC)},
  pages        = {1--7},
  year         = {2020},
  organization = {IEEE}
}

@article{hadfield2019quantum,
  title     = {From the quantum approximate optimization algorithm to a quantum alternating operator ansatz},
  author    = {Hadfield, Stuart and Wang, Zhihui and O'gorman, Bryan and Rieffel, Eleanor G and Venturelli, Davide and Biswas, Rupak},
  journal   = {Algorithms},
  volume    = {12},
  number    = {2},
  pages     = {34},
  year      = {2019},
  publisher = {MDPI}
}

@article{butcher1996history,
  title     = {A history of Runge-Kutta methods},
  author    = {Butcher, John Charles},
  journal   = {Applied numerical mathematics},
  volume    = {20},
  number    = {3},
  pages     = {247--260},
  year      = {1996},
  publisher = {Elsevier}
}

@article{li2022ode,
  title   = {ODE transformer: An ordinary differential equation-inspired model for sequence generation},
  author  = {Li, Bei and Du, Quan and Zhou, Tao and Jing, Yi and Zhou, Shuhan and Zeng, Xin and Xiao, Tong and Zhu, Jingbo and Liu, Xuebo and Zhang, Min},
  journal = {arXiv preprint arXiv:2203.09176},
  year    = {2022}
}

@article{zhong2022neural,
  title   = {A neural ode interpretation of transformer layers},
  author  = {Zhong, Yaofeng Desmond and Zhang, Tongtao and Chakraborty, Amit and Dey, Biswadip},
  journal = {arXiv preprint arXiv:2212.06011},
  year    = {2022}
}

@article{breuckmann2018scalable,
  title     = {Scalable neural network decoders for higher dimensional quantum codes},
  author    = {Breuckmann, Nikolas P and Ni, Xiaotong},
  journal   = {Quantum},
  volume    = {2},
  pages     = {68},
  year      = {2018},
  publisher = {Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

