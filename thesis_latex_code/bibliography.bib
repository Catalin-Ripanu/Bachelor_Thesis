@inproceedings{goodfellow2014generative,
  title     = {Generative adversarial nets},
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle = {Advances in neural information processing systems},
  pages     = {2672--2680},
  year      = {2014}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@book{nielsen2001quantum,
  title     = {Quantum computation and quantum information},
  author    = {Nielsen, Michael A and Chuang, Isaac L},
  volume    = {2},
  year      = {2001},
  publisher = {Cambridge university press Cambridge}
}

@article{lau2022nisq,
  title     = {NISQ computing: where are we and where do we go?},
  author    = {Lau, Jonathan Wei Zhong and Lim, Kian Hwee and Shrotriya, Harshank and Kwek, Leong Chuan},
  journal   = {AAPPS bulletin},
  volume    = {32},
  number    = {1},
  pages     = {27},
  year      = {2022},
  publisher = {Springer}
}

@article{huang2021power,
  title     = {Power of data in quantum machine learning},
  author    = {Huang, Hsin-Yuan and Broughton, Michael and Mohseni, Masoud and Babbush, Ryan and Boixo, Sergio and Neven, Hartmut and McClean, Jarrod R},
  journal   = {Nature communications},
  volume    = {12},
  number    = {1},
  pages     = {2631},
  year      = {2021},
  publisher = {Nature Publishing Group UK London}
}

@inproceedings{furer2008solving,
  title        = {Solving NP-complete problems with quantum search},
  author       = {F{\"u}rer, Martin},
  booktitle    = {Latin American Symposium on Theoretical Informatics},
  pages        = {784--792},
  year         = {2008},
  organization = {Springer}
}

@misc{farahani2020brief,
  title         = {A Brief Review of Domain Adaptation},
  author        = {Abolfazl Farahani and Sahar Voghoei and Khaled Rasheed and Hamid R. Arabnia},
  year          = {2020},
  eprint        = {2010.03978},
  archiveprefix = {arXiv},
  primaryclass  = {id='cs.LG' full_name='Machine Learning' is_active=True alt_name=None in_archive='cs' is_general=False description='Papers on all aspects of machine learning research (supervised, unsupervised, reinforcement learning, bandit problems, and so on) including also robustness, explanation, fairness, and methodology. cs.LG is also an appropriate primary category for applications of machine learning methods.'}
}

@misc{hinton2015distilling,
  title         = {Distilling the Knowledge in a Neural Network},
  author        = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
  year          = {2015},
  eprint        = {1503.02531},
  archiveprefix = {arXiv},
  primaryclass  = {id='stat.ML' full_name='Machine Learning' is_active=True alt_name=None in_archive='stat' is_general=False description='Covers machine learning papers (supervised, unsupervised, semi-supervised learning, graphical models, reinforcement learning, bandits, high dimensional inference, etc.) with a statistical or theoretical grounding'}
}

@article{Horodecki_2009,
  title     = {Quantum entanglement},
  volume    = {81},
  issn      = {1539-0756},
  url       = {http://dx.doi.org/10.1103/RevModPhys.81.865},
  doi       = {10.1103/revmodphys.81.865},
  number    = {2},
  journal   = {Reviews of Modern Physics},
  publisher = {American Physical Society (APS)},
  author    = {Horodecki, Ryszard and Horodecki, Paweł and Horodecki, Michał and Horodecki, Karol},
  year      = {2009},
  month     = jun,
  pages     = {865–942}
}


@article{chatterjee2024solving,
  title     = {Solving various NP-hard problems using exponentially fewer qubits on a quantum computer},
  author    = {Chatterjee, Yagnik and Bourreau, Eric and Ran{\v{c}}i{\'c}, Marko J},
  journal   = {Physical Review A},
  volume    = {109},
  number    = {5},
  pages     = {052441},
  year      = {2024},
  publisher = {APS}
}

@misc{koprinkov2023quantum,
  title         = {The quantum superposition principle: a reconsideration},
  author        = {Ivan Georgiev Koprinkov},
  year          = {2023},
  eprint        = {2311.02391},
  archiveprefix = {arXiv},
  primaryclass  = {id='physics.gen-ph' full_name='General Physics' is_active=True alt_name=None in_archive='physics' is_general=True description=None}
}

@article{benedetti2019parameterized,
  title     = {Parameterized quantum circuits as machine learning models},
  author    = {Benedetti, Marcello and Lloyd, Erika and Sack, Stefan and Fiorentini, Mattia},
  journal   = {Quantum Science and Technology},
  volume    = {4},
  number    = {4},
  pages     = {043001},
  year      = {2019},
  publisher = {IOP Publishing}
}

@article{bradbury2018jax,
  title  = {JAX: composable transformations of Python+ NumPy programs},
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and others},
  year   = {2018}
}

@article{Zhang_2023,
  title     = {TensorCircuit: a Quantum Software Framework for the NISQ Era},
  volume    = {7},
  issn      = {2521-327X},
  url       = {http://dx.doi.org/10.22331/q-2023-02-02-912},
  doi       = {10.22331/q-2023-02-02-912},
  journal   = {Quantum},
  publisher = {Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
  author    = {Zhang, Shi-Xin and Allcock, Jonathan and Wan, Zhou-Quan and Liu, Shuo and Sun, Jiace and Yu, Hao and Yang, Xing-Han and Qiu, Jiezhong and Ye, Zhaofeng and Chen, Yu-Qin and Lee, Chee-Kong and Zheng, Yi-Cong and Jian, Shao-Kai and Yao, Hong and Hsieh, Chang-Yu and Zhang, Shengyu},
  year      = {2023},
  month     = feb,
  pages     = {912}
}


@article{imambi2021pytorch,
  title     = {PyTorch},
  author    = {Imambi, Sagar and Prakash, Kolla Bhanu and Kanagachidambaresan, GR},
  journal   = {Programming with TensorFlow: Solution for Edge Computing Applications},
  pages     = {87--104},
  year      = {2021},
  publisher = {Springer}
}

@inproceedings{cross2018ibm,
  title     = {The IBM Q experience and QISKit open-source quantum computing software},
  author    = {Cross, Andrew},
  booktitle = {APS March meeting abstracts},
  volume    = {2018},
  pages     = {L58--003},
  year      = {2018}
}

@article{broughton2020tensorflow,
  title   = {Tensorflow quantum: A software framework for quantum machine learning},
  author  = {Broughton, Michael and Verdon, Guillaume and McCourt, Trevor and Martinez, Antonio J and Yoo, Jae Hyeon and Isakov, Sergei V and Massey, Philip and Halavati, Ramin and Niu, Murphy Yuezhen and Zlokapa, Alexander and others},
  journal = {arXiv preprint arXiv:2003.02989},
  year    = {2020}
}

@article{heek2020flax,
  title   = {Flax: A neural network library and ecosystem for JAX},
  author  = {Heek, Jonathan and Levskaya, Anselm and Oliver, Avital and Ritter, Marvin and Rondepierre, Bertrand and Steiner, Andreas and van Zee, Marc},
  journal = {Version 0.3},
  volume  = {3},
  pages   = {14--26},
  year    = {2020}
}

@article{dunjko2018machine,
  title     = {Machine learning \& artificial intelligence in the quantum domain: a review of recent progress},
  author    = {Dunjko, Vedran and Briegel, Hans J},
  journal   = {Reports on Progress in Physics},
  volume    = {81},
  number    = {7},
  pages     = {074001},
  year      = {2018},
  publisher = {IOP Publishing}
}

@misc{wang2024comprehensive,
  title         = {A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance},
  author        = {Yunfei Wang and Junyu Liu},
  year          = {2024},
  eprint        = {2401.11351},
  archiveprefix = {arXiv},
  primaryclass  = {id='quant-ph' full_name='Quantum Physics' is_active=True alt_name=None in_archive='quant-ph' is_general=False description=None}
}

@article{hu2021forcenet,
  title   = {Forcenet: A graph neural network for large-scale quantum calculations},
  author  = {Hu, Weihua and Shuaibi, Muhammed and Das, Abhishek and Goyal, Siddharth and Sriram, Anuroop and Leskovec, Jure and Parikh, Devi and Zitnick, C Lawrence},
  journal = {arXiv preprint arXiv:2103.01436},
  year    = {2021}
}

@article{narayanan2000quantum,
  title     = {Quantum artificial neural network architectures and components},
  author    = {Narayanan, Ajit and Menneer, Tammy},
  journal   = {Information Sciences},
  volume    = {128},
  number    = {3-4},
  pages     = {231--255},
  year      = {2000},
  publisher = {Elsevier}
}

@article{johri2021nearest,
  title     = {Nearest centroid classification on a trapped ion quantum computer},
  author    = {Johri, Sonika and Debnath, Shantanu and Mocherla, Avinash and Singk, Alexandros and Prakash, Anupam and Kim, Jungsang and Kerenidis, Iordanis},
  journal   = {npj Quantum Information},
  volume    = {7},
  number    = {1},
  pages     = {122},
  year      = {2021},
  publisher = {Nature Publishing Group UK London}
}

@article{wiebe2015quantum,
  title   = {Quantum nearest-neighbor algorithms for machine learning},
  author  = {Wiebe, Nathan and Kapoor, Ashish and Svore, Krysta M},
  journal = {Quantum information and computation},
  volume  = {15},
  number  = {3-4},
  pages   = {318--358},
  year    = {2015}
}

@article{rebentrost2014quantum,
  title     = {Quantum support vector machine for big data classification},
  author    = {Rebentrost, Patrick and Mohseni, Masoud and Lloyd, Seth},
  journal   = {Physical review letters},
  volume    = {113},
  number    = {13},
  pages     = {130503},
  year      = {2014},
  publisher = {APS}
}

@article{cerezo2021variational,
  title     = {Variational quantum algorithms},
  author    = {Cerezo, Marco and Arrasmith, Andrew and Babbush, Ryan and Benjamin, Simon C and Endo, Suguru and Fujii, Keisuke and McClean, Jarrod R and Mitarai, Kosuke and Yuan, Xiao and Cincio, Lukasz and others},
  journal   = {Nature Reviews Physics},
  volume    = {3},
  number    = {9},
  pages     = {625--644},
  year      = {2021},
  publisher = {Nature Publishing Group UK London}
}

@article{liashchynskyi2019grid,
  title   = {Grid search, random search, genetic algorithm: a big comparison for NAS},
  author  = {Liashchynskyi, Petro and Liashchynskyi, Pavlo},
  journal = {arXiv preprint arXiv:1912.06059},
  year    = {2019}
}

@inproceedings{ogutu2012genomic,
  title        = {Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions},
  author       = {Ogutu, Joseph O and Schulz-Streeck, Torben and Piepho, Hans-Peter},
  booktitle    = {BMC proceedings},
  volume       = {6},
  pages        = {1--6},
  year         = {2012},
  organization = {Springer}
}

@article{abbas2021power,
  title     = {The power of quantum neural networks},
  author    = {Abbas, Amira and Sutter, David and Zoufal, Christa and Lucchi, Aur{\'e}lien and Figalli, Alessio and Woerner, Stefan},
  journal   = {Nature Computational Science},
  volume    = {1},
  number    = {6},
  pages     = {403--409},
  year      = {2021},
  publisher = {Nature Publishing Group US New York}
}

@article{pon2021hyperparameter,
  title   = {Hyperparameter tuning of deep learning models in keras},
  author  = {Pon, Mohamad Zaim Awang and KK, Krishna Prakash},
  journal = {Sparklinglight Transactions on Artificial Intelligence and Quantum Computing (STAIQC)},
  volume  = {1},
  number  = {1},
  pages   = {36--40},
  year    = {2021}
}

@inproceedings{fan2024quantum,
  title     = {Quantum-Inspired Neural Network with Runge-Kutta Method},
  author    = {Fan, Zipeng and Zhang, Jing and Zhang, Peng and Lin, Qianxi and Gao, Hui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {38},
  number    = {16},
  pages     = {17977--17984},
  year      = {2024}
}

@misc{tensormnist,
  title  = {mnist},
  author = {Tensorflow},
  year   = {2019}
}

@misc{berrar2019cross,
  title  = {Cross-validation.},
  author = {Berrar, Daniel and others},
  year   = {2019}
}

@article{popescu2009multilayer,
  title     = {Multilayer perceptron and neural networks},
  author    = {Popescu, Marius-Constantin and Balas, Valentina E and Perescu-Popescu, Liliana and Mastorakis, Nikos},
  journal   = {WSEAS Transactions on Circuits and Systems},
  volume    = {8},
  number    = {7},
  pages     = {579--588},
  year      = {2009},
  publisher = {World Scientific and Engineering Academy and Society (WSEAS) Stevens Point~…}
}

@article{gulde2003implementation,
  title     = {Implementation of the Deutsch--Jozsa algorithm on an ion-trap quantum computer},
  author    = {Gulde, Stephan and Riebe, Mark and Lancaster, Gavin PT and Becher, Christoph and Eschner, J{\"u}rgen and H{\"a}ffner, Hartmut and Schmidt-Kaler, Ferdinand and Chuang, Isaac L and Blatt, Rainer},
  journal   = {Nature},
  volume    = {421},
  number    = {6918},
  pages     = {48--50},
  year      = {2003},
  publisher = {Nature Publishing Group UK London}
}

@article{weinstein2001implementation,
  title     = {Implementation of the quantum Fourier transform},
  author    = {Weinstein, Yaakov S and Pravia, MA and Fortunato, EM and Lloyd, Seth and Cory, David G},
  journal   = {Physical review letters},
  volume    = {86},
  number    = {9},
  pages     = {1889},
  year      = {2001},
  publisher = {APS}
}

@article{o2019quantum,
  title     = {Quantum phase estimation of multiple eigenvalues for small-scale (noisy) experiments},
  author    = {O'Brien, Thomas E and Tarasinski, Brian and Terhal, Barbara M},
  journal   = {New Journal of Physics},
  volume    = {21},
  number    = {2},
  pages     = {023022},
  year      = {2019},
  publisher = {IOP Publishing}
}

@article{shi2017coherence,
  title     = {Coherence depletion in the Grover quantum search algorithm},
  author    = {Shi, Hai-Long and Liu, Si-Yuan and Wang, Xiao-Hui and Yang, Wen-Li and Yang, Zhan-Ying and Fan, Heng},
  journal   = {Physical Review A},
  volume    = {95},
  number    = {3},
  pages     = {032307},
  year      = {2017},
  publisher = {APS}
}

@inproceedings{NIPS2017_a96b65a7,
  author    = {Li, Yuanzhi and Yuan, Yang},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Convergence Analysis of Two-layer Neural Networks with ReLU Activation},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/a96b65a721e561e1e3de768ac819ffbb-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@article{srivastava2014dropout,
  title     = {Dropout: a simple way to prevent neural networks from overfitting},
  author    = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal   = {The journal of machine learning research},
  volume    = {15},
  number    = {1},
  pages     = {1929--1958},
  year      = {2014},
  publisher = {JMLR. org}
}

@misc{cordonnier2020relationship,
  title         = {On the Relationship between Self-Attention and Convolutional Layers},
  author        = {Jean-Baptiste Cordonnier and Andreas Loukas and Martin Jaggi},
  year          = {2020},
  eprint        = {1911.03584},
  archiveprefix = {arXiv},
  primaryclass  = {id='cs.LG' full_name='Machine Learning' is_active=True alt_name=None in_archive='cs' is_general=False description='Papers on all aspects of machine learning research (supervised, unsupervised, reinforcement learning, bandit problems, and so on) including also robustness, explanation, fairness, and methodology. cs.LG is also an appropriate primary category for applications of machine learning methods.'}
}

@article{loshchilov2017decoupled,
  title   = {Decoupled weight decay regularization},
  author  = {Loshchilov, Ilya and Hutter, Frank},
  journal = {arXiv preprint arXiv:1711.05101},
  year    = {2017}
}

@inproceedings{7986470,
  author    = {Qolomany, Basheer and Maabreh, Majdi and Al-Fuqaha, Ala and Gupta, Ajay and Benhaddou, Driss},
  booktitle = {2017 13th International Wireless Communications and Mobile Computing Conference (IWCMC)},
  title     = {Parameters optimization of deep learning models using Particle swarm optimization},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {1285-1290},
  keywords  = {Machine learning;Neurons;Computational modeling;Optimization;Biological neural networks;Sociology;Statistics;smart building services;deep machine learning;parameter optimization;particle swarm optimization},
  doi       = {10.1109/IWCMC.2017.7986470}
}


@inproceedings{pmlr-v70-kim17b,
  title     = {{S}plit{N}et: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization},
  author    = {Juyong Kim and Yookoon Park and Gunhee Kim and Sung Ju Hwang},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages     = {1866--1874},
  year      = {2017},
  editor    = {Precup, Doina and Teh, Yee Whye},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  month     = {06--11 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v70/kim17b/kim17b.pdf},
  url       = {https://proceedings.mlr.press/v70/kim17b.html},
  abstract  = {We propose a novel deep neural network that is both lightweight and effectively structured for model parallelization. Our network, which we name as SplitNet, automatically learns to split the network weights into either a set or a hierarchy of multiple groups that use disjoint sets of features, by learning both the class-to-group and feature-to-group assignment matrices along with the network weights. This produces a tree-structured network that involves no connection between branched subtrees of semantically disparate class groups. SplitNet thus greatly reduces the number of parameters and requires significantly less computations, and is also embarrassingly model parallelizable at test time, since the network evaluation for each subnetwork is completely independent except for the shared lower layer weights that can be duplicated over multiple processors. We validate our method with two deep network models (ResNet and AlexNet) on two different datasets (CIFAR-100 and ILSVRC 2012) for image classification, on which our method obtains networks with significantly reduced number of parameters while achieving comparable or superior classification accuracies over original full deep networks, and accelerated test speed with multiple GPUs.}
}


@article{wen2021convolutional,
  title     = {Convolutional neural network with automatic learning rate scheduler for fault classification},
  author    = {Wen, Long and Gao, Liang and Li, Xinyu and Zeng, Bing},
  journal   = {IEEE Transactions on Instrumentation and Measurement},
  volume    = {70},
  pages     = {1--12},
  year      = {2021},
  publisher = {IEEE}
}

@inproceedings{bottou2010large,
  title        = {Large-scale machine learning with stochastic gradient descent},
  author       = {Bottou, L{\'e}on},
  booktitle    = {Proceedings of COMPSTAT'2010: 19th International Conference on Computational StatisticsParis France, August 22-27, 2010 Keynote, Invited and Contributed Papers},
  pages        = {177--186},
  year         = {2010},
  organization = {Springer}
}

@inproceedings{zhang2018improved,
  title        = {Improved adam optimizer for deep neural networks},
  author       = {Zhang, Zijun},
  booktitle    = {2018 IEEE/ACM 26th international symposium on quality of service (IWQoS)},
  pages        = {1--2},
  year         = {2018},
  organization = {Ieee}
}

@article{zamanlooy2013efficient,
  title     = {Efficient VLSI implementation of neural networks with hyperbolic tangent activation function},
  author    = {Zamanlooy, Babak and Mirhassani, Mitra},
  journal   = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  volume    = {22},
  number    = {1},
  pages     = {39--48},
  year      = {2013},
  publisher = {IEEE}
}

@inproceedings{han1995influence,
  title        = {The influence of the sigmoid function parameters on the speed of backpropagation learning},
  author       = {Han, Jun and Moraga, Claudio},
  booktitle    = {International workshop on artificial neural networks},
  pages        = {195--201},
  year         = {1995},
  organization = {Springer}
}

@inproceedings{hinton2011transforming,
  title        = {Transforming auto-encoders},
  author       = {Hinton, Geoffrey E and Krizhevsky, Alex and Wang, Sida D},
  booktitle    = {Artificial Neural Networks and Machine Learning--ICANN 2011: 21st International Conference on Artificial Neural Networks, Espoo, Finland, June 14-17, 2011, Proceedings, Part I 21},
  pages        = {44--51},
  year         = {2011},
  organization = {Springer}
}

@misc{alvarez2018learning,
  title         = {Learning the Number of Neurons in Deep Networks},
  author        = {Jose M Alvarez and Mathieu Salzmann},
  year          = {2018},
  eprint        = {1611.06321},
  archiveprefix = {arXiv},
  primaryclass  = {id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}

@inproceedings{Szegedy_2015_CVPR,
  author    = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  title     = {Going Deeper With Convolutions},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2015}
}

@article{dutta2021redesigning,
  title   = {Redesigning the transformer architecture with insights from multi-particle dynamical systems},
  author  = {Dutta, Subhabrata and Gautam, Tanya and Chakrabarti, Soumen and Chakraborty, Tanmoy},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  pages   = {5531--5544},
  year    = {2021}
}

@article{lu2019understanding,
  title   = {Understanding and improving transformer from a multi-particle dynamic system point of view},
  author  = {Lu, Yiping and Li, Zhuohan and He, Di and Sun, Zhiqing and Dong, Bin and Qin, Tao and Wang, Liwei and Liu, Tie-Yan},
  journal = {arXiv preprint arXiv:1906.02762},
  year    = {2019}
}

@incollection{bottou2012stochastic,
  title     = {Stochastic gradient descent tricks},
  author    = {Bottou, L{\'e}on},
  booktitle = {Neural Networks: Tricks of the Trade: Second Edition},
  pages     = {421--436},
  year      = {2012},
  publisher = {Springer}
}

@misc{randomsearch,
  title        = {Random Search},
  author       = {M. Hammad Hassan},
  year         = {2023},
  howpublished = {\url{https://medium.com/@hammad.ai/tuning-model-hyperparameters-with-random-search-f4c1cc88f528}}
}

@misc{crossvalidation,
  title        = {What is Cross-Validation?},
  author       = {Mohammed Alhamid},
  year         = {2020},
  howpublished = {\url{https://towardsdatascience.com/what-is-cross-validation-60c01f9d9e75}}
}

@misc{learningrate2,
  title        = {Learning Rate Scheduler - Overview},
  author       = {Cloud Factory},
  year         = {2024},
  howpublished = {\url{https://wiki.cloudfactory.com/docs/mp-wiki/scheduler/overview-of-learning-rate-schedulers-in-ml}}
}

@misc{weightdecay,
  title        = {Weight Decay in Deep Learning},
  author       = {Sujatha Mudadla},
  year         = {2023},
  howpublished = {\url{https://medium.com/@sujathamudadla1213/weight-decay-in-deep-learning-8fb8b5dd825c}}
}

@misc{odes,
  title        = {Ordinary differential equations},
  author       = {Vahid Shahrezaei},
  year         = {2021},
  howpublished = {\url{https://bookdown.org/vshahrez/lecture-notes/introduction-to-ordinary-differential-equations.html}}
}

@misc{learningrate,
  title        = {Learning Rate Scheduler},
  author       = {Shreenidhi Sudhakar},
  year         = {2017},
  howpublished = {\url{https://towardsdatascience.com/learning-rate-scheduler-d8a55747dd90}}
}

@misc{randomsearch2,
  title        = {Random Search in Machine Learning},
  author       = {Binoy},
  year         = {2023},
  howpublished = {\url{https://www.scaler.com/topics/machine-learning/random-search-in-machine-learning/}}
}

@misc{gan-photo,
  title        = {Generative Adversarial Network (GAN)},
  author       = {BRYON MOYER},
  year         = {2021},
  howpublished = {\url{https://semiengineering.com/knowledge_centers/artificial-intelligence/neural-networks/generative-adversarial-network-gan/}}
}

@misc{vit,
  title        = {Vision Transformers},
  author       = {Tauseef Ahmad},
  year         = 2024,
  howpublished = {\url{https://medium.com/@tauseefahmad12/vision-transformers-4c6116f7f0ce}}
}

@misc{gan,
  title        = {Generative Adversarial Networks},
  author       = {Marco Del Pra},
  year         = 2023,
  howpublished = {\url{https://medium.com/@marcodelpra/generative-adversarial-networks-dba10e1b4424}}
}

@misc{mlp,
  title        = {Multi-Layer Perceptron vs. Deep Neural Network},
  author       = {baeldung},
  year         = 2023,
  howpublished = {\url{https://www.baeldung.com/cs/mlp-vs-dnn}}
}

@misc{ann,
  title        = {Artificial neural network(ANN)},
  author       = {Morjina akter},
  year         = 2023,
  howpublished = {\url{https://medium.com/@morjina/artificial-neural-network-ann-74eae97980ea}}
}


@misc{deeplearning,
  title        = {Deep Learning Fundamental},
  author       = {Anshu Mishra},
  year         = 2019,
  howpublished = {\url{https://medium.datadriveninvestor.com/deep-learning-fundamental-important-concepts-59d7ae90901b}}
}

@misc{adamoptimizerw,
  title        = {Why AdamW matters},
  author       = {Fabio M. Graetz},
  year         = 2018,
  howpublished = {\url{https://towardsdatascience.com/why-adamw-matters-736223f31b5d}}
}

@misc{gradientdescent,
  title        = {Gradient Descent Algorithm},
  author       = {Robert Kwiatkowski},
  year         = 2021,
  howpublished = {\url{https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21}}
}

@misc{machinelearning,
  title        = {A Brief Overview of Machine Learning},
  author       = {Suhas Maddali},
  year         = 2022,
  howpublished = {\url{https://towardsdatascience.com/a-brief-overview-of-machine-learning-20abc68cbd4e}}
}

@article{jiang2021transgan,
  title   = {Transgan: Two pure transformers can make one strong gan, and that can scale up},
  author  = {Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  pages   = {14745--14758},
  year    = {2021}
}

@article{Comajoan_Cara_2024,
  title     = {Quantum Vision Transformers for Quark-Gluon Classification},
  volume    = {13},
  issn      = {2075-1680},
  url       = {http://dx.doi.org/10.3390/axioms13050323},
  doi       = {10.3390/axioms13050323},
  number    = {5},
  journal   = {Axioms},
  publisher = {MDPI AG},
  author    = {Comajoan Cara, Marçal and Dahale, Gopal Ramesh and Dong, Zhongtian and Forestano, Roy T. and Gleyzer, Sergei and Justice, Daniel and Kong, Kyoungchul and Magorsch, Tom and Matchev, Konstantin T. and Matcheva, Katia and Unlu, Eyup B.},
  year      = {2024},
  month     = may,
  pages     = {323}
}

@article{ILSVRC15,
  author  = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title   = { {ImageNet Large Scale Visual Recognition Challenge} },
  year    = {2015},
  journal = {International Journal of Computer Vision (IJCV)},
  doi     = {10.1007/s11263-015-0816-y},
  volume  = {115},
  number  = {3},
  pages   = {211-252}
}

@article{weiss2016survey,
  title     = {A survey of transfer learning},
  author    = {Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
  journal   = {Journal of Big data},
  volume    = {3},
  pages     = {1--40},
  year      = {2016},
  publisher = {Springer}
}

@article{voita2019analyzing,
  title   = {Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned},
  author  = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  journal = {arXiv preprint arXiv:1905.09418},
  year    = {2019}
}

@inproceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@software{ahmet_sarigun_2024_10806360,
  author    = {Ahmet Sarıgün},
  title     = {{Re-Implementation of TransGAN: Two Transformers 
               Can Make One Strong GAN}},
  month     = mar,
  year      = 2024,
  publisher = {Zenodo},
  version   = {v2.1},
  doi       = {10.5281/zenodo.10806360},
  url       = {https://doi.org/10.5281/zenodo.10806360}
}

@article{liu2020understanding,
  title   = {Understanding the difficulty of training transformers},
  author  = {Liu, Liyuan and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu and Han, Jiawei},
  journal = {arXiv preprint arXiv:2004.08249},
  year    = {2020}
}

@inproceedings{di2022dawn,
  title        = {The dawn of quantum natural language processing},
  author       = {Di Sipio, Riccardo and Huang, Jia-Hong and Chen, Samuel Yen-Chi and Mangini, Stefano and Worring, Marcel},
  booktitle    = {ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages        = {8612--8616},
  year         = {2022},
  organization = {IEEE}
}

@article{he2020infusing,
  title   = {Infusing disease knowledge into BERT for health question answering, medical inference and disease name recognition},
  author  = {He, Yun and Zhu, Ziwei and Zhang, Yin and Chen, Qin and Caverlee, James},
  journal = {arXiv preprint arXiv:2010.03746},
  year    = {2020}
}

@article{lecun2010mnist,
  title   = {MNIST handwritten digit database},
  author  = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume  = {2},
  year    = {2010}
}

@article{Reyes_2021,
  title     = {Simulation of quantum many-body systems on Amazon cloud},
  volume    = {261},
  issn      = {0010-4655},
  url       = {http://dx.doi.org/10.1016/j.cpc.2020.107750},
  doi       = {10.1016/j.cpc.2020.107750},
  journal   = {Computer Physics Communications},
  publisher = {Elsevier BV},
  author    = {Reyes, Justin A. and Marinescu, Dan C. and Mucciolo, Eduardo R.},
  year      = {2021},
  month     = apr,
  pages     = {107750}
}

@inproceedings{Mykhailova_2023,
  title     = {Teaching Quantum Computing Using Microsoft Quantum Development Kit and Azure Quantum},
  url       = {http://dx.doi.org/10.1109/QCE57702.2023.20320},
  doi       = {10.1109/qce57702.2023.20320},
  booktitle = {2023 IEEE International Conference on Quantum Computing and Engineering (QCE)},
  publisher = {IEEE},
  author    = {Mykhailova, Mariia},
  year      = {2023},
  month     = sep
}

@misc{kalai2023googles,
  title         = {Google's Quantum Supremacy Claim: Data, Documentation, and Discussion},
  author        = {Gil Kalai and Yosef Rinott and Tomer Shoham},
  year          = {2023},
  eprint        = {2210.12753},
  archiveprefix = {arXiv},
  primaryclass  = {id='quant-ph' full_name='Quantum Physics' is_active=True alt_name=None in_archive='quant-ph' is_general=False description=None}
}

@article{Santos_2016,
  title     = {O Computador Quântico da IBM e o IBM Quantum Experience},
  volume    = {39},
  issn      = {1806-1117},
  url       = {http://dx.doi.org/10.1590/1806-9126-RBEF-2016-0155},
  doi       = {10.1590/1806-9126-rbef-2016-0155},
  number    = {1},
  journal   = {Revista Brasileira de Ensino de Física},
  publisher = {FapUNIFESP (SciELO)},
  author    = {Santos, Alan C.},
  year      = {2016},
  month     = sep
}

@techreport{Krizhevsky09learningmultiple,
  author      = {Alex Krizhevsky},
  title       = {Learning multiple layers of features from tiny images},
  institution = {},
  year        = {2009}
}

@article{dosovitskiy2020,
  title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal = {arXiv preprint arXiv:2010.11929},
  year    = {2020}
}

@inproceedings{zhao2020diffaugment,
  title     = {Differentiable Augmentation for Data-Efficient GAN Training},
  author    = {Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song},
  booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
  year      = {2020}
}

@article{liu2016large,
  title   = {Large-margin softmax loss for convolutional neural networks},
  author  = {Liu, Weiyang and Wen, Yandong and Yu, Zhiding and Yang, Meng},
  journal = {arXiv preprint arXiv:1612.02295},
  year    = {2016}
}

@article{hendrycks2016gaussian,
  title   = {Gaussian error linear units (gelus)},
  author  = {Hendrycks, Dan and Gimpel, Kevin},
  journal = {arXiv preprint arXiv:1606.08415},
  year    = {2016}
}

@article{chen2014big,
  title     = {Big data deep learning: challenges and perspectives},
  author    = {Chen, Xue-Wen and Lin, Xiaotong},
  journal   = {IEEE access},
  volume    = {2},
  pages     = {514--525},
  year      = {2014},
  publisher = {Ieee}
}

@article{barenco1995elementary,
  title     = {Elementary gates for quantum computation},
  author    = {Barenco, Adriano and Bennett, Charles H and Cleve, Richard and DiVincenzo, David P and Margolus, Norman and Shor, Peter and Sleator, Tycho and Smolin, John A and Weinfurter, Harald},
  journal   = {Physical review A},
  volume    = {52},
  number    = {5},
  pages     = {3457},
  year      = {1995},
  publisher = {APS}
}

@article{wu2018prodsumnet,
  title   = {ProdSumNet: reducing model parameters in deep neural networks via product-of-sums matrix decompositions},
  author  = {Wu, Chai Wah},
  journal = {arXiv preprint arXiv:1809.02209},
  year    = {2018}
}

@article{azadbakht2022drastically,
  title   = {Drastically Reducing the Number of Trainable Parameters in Deep CNNs by Inter-layer Kernel-sharing},
  author  = {Azadbakht, Alireza and Kheradpisheh, Saeed Reza and Khalfaoui-Hassani, Ismail and Masquelier, Timoth{\'e}e},
  journal = {arXiv preprint arXiv:2210.14151},
  year    = {2022}
}

@inproceedings{xu2020reluplex,
  title        = {Reluplex made more practical: Leaky ReLU},
  author       = {Xu, Jin and Li, Zishan and Du, Bowen and Zhang, Miaomiao and Liu, Jing},
  booktitle    = {2020 IEEE Symposium on Computers and communications (ISCC)},
  pages        = {1--7},
  year         = {2020},
  organization = {IEEE}
}

@article{hadfield2019quantum,
  title     = {From the quantum approximate optimization algorithm to a quantum alternating operator ansatz},
  author    = {Hadfield, Stuart and Wang, Zhihui and O'gorman, Bryan and Rieffel, Eleanor G and Venturelli, Davide and Biswas, Rupak},
  journal   = {Algorithms},
  volume    = {12},
  number    = {2},
  pages     = {34},
  year      = {2019},
  publisher = {MDPI}
}

@article{butcher1996history,
  title     = {A history of Runge-Kutta methods},
  author    = {Butcher, John Charles},
  journal   = {Applied numerical mathematics},
  volume    = {20},
  number    = {3},
  pages     = {247--260},
  year      = {1996},
  publisher = {Elsevier}
}

@article{li2022ode,
  title   = {ODE transformer: An ordinary differential equation-inspired model for sequence generation},
  author  = {Li, Bei and Du, Quan and Zhou, Tao and Jing, Yi and Zhou, Shuhan and Zeng, Xin and Xiao, Tong and Zhu, Jingbo and Liu, Xuebo and Zhang, Min},
  journal = {arXiv preprint arXiv:2203.09176},
  year    = {2022}
}

@article{zhong2022neural,
  title   = {A neural ode interpretation of transformer layers},
  author  = {Zhong, Yaofeng Desmond and Zhang, Tongtao and Chakraborty, Amit and Dey, Biswadip},
  journal = {arXiv preprint arXiv:2212.06011},
  year    = {2022}
}

@article{breuckmann2018scalable,
  title     = {Scalable neural network decoders for higher dimensional quantum codes},
  author    = {Breuckmann, Nikolas P and Ni, Xiaotong},
  journal   = {Quantum},
  volume    = {2},
  pages     = {68},
  year      = {2018},
  publisher = {Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

